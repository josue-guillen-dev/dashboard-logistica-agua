### ğŸ’§ End-to-End Data Pipeline & BI Dashboard | Planta Purificadora de Agua

ğŸ”— **Demo del Proyecto:** [Inserta el enlace a tu Streamlit aquÃ­]

## ğŸ“Œ DescripciÃ³n General
Proyecto integral de IngenierÃ­a de Datos y Business Intelligence desarrollado para automatizar la consolidaciÃ³n operativa y financiera de una planta purificadora de agua. 

La soluciÃ³n reemplaza un proceso manual y propenso a errores (basado en mÃºltiples planillas desestructuradas enviadas por choferes) por un flujo automatizado (ETL) que extrae, limpia, estandariza y consolida los datos en una base relacional, alimentando un dashboard interactivo para el control gerencial.

## ğŸ¯ Objetivo del Proyecto y Problema de Negocio
**Problemas detectados:**
* Falta de visibilidad diaria de ventas por ruta.
* Datos desordenados y no estandarizados (errores de tipeo, formatos inconsistentes).
* Dificultad para consolidar ingresos y gastos rÃ¡pidamente.
* Ausencia de mÃ©tricas claras para la toma de decisiones.

**SoluciÃ³n aportada:** Un sistema End-to-End que centraliza la informaciÃ³n y proporciona KPIs financieros y operativos en tiempo real.

## ğŸ—ï¸ Arquitectura del Sistema

```text
[Google Drive / Google Sheets] (Fuentes de Datos Desestructuradas)
            â”‚
            â–¼
[pipeline_etl.py] (ExtracciÃ³n, Limpieza y TransformaciÃ³n - Pandas/Google API)
            â”‚
            â–¼
[SQLite / db_portafolio.db] (Almacenamiento Relacional Estructurado)
            â”‚
            â–¼
[app.py] (Streamlit Dashboard - VisualizaciÃ³n Interactiva)
âš™ï¸ Componentes del Proyecto
1ï¸âƒ£ Pipeline ETL (pipeline_etl.py)
Motor automatizado de extracciÃ³n y limpieza que:
Se conecta a la API de Google Workspace.
Navega subcarpetas dinÃ¡micamente para buscar archivos histÃ³ricos y diarios.
Extrae informaciÃ³n desestructurada e identifica columnas mediante "anclas" lÃ³gicas.
Aplica limpieza avanzada: estandarizaciÃ³n de fechas irregulares a formato SQL (YYYY-MM-DD), conversiÃ³n de strings a formatos de moneda reales y normalizaciÃ³n de categorÃ­as.

Consolida y carga los datos estructurados en una base de datos SQLite.

2ï¸âƒ£ Dashboard Interactivo (app.py)
AplicaciÃ³n web desarrollada con Streamlit que actÃºa como Panel de Control Gerencial:
Filtros DinÃ¡micos: BÃºsqueda por fechas, clientes, productos y comunas.
MÃ©tricas Clave (KPIs): Ventas totales, mejor cliente, mes de mayor facturaciÃ³n y control de fugas de capital.
Visualizaciones: GrÃ¡ficos interactivos de Plotly Express y herramientas nativas de Streamlit para analizar el rendimiento por chofer, ventas adicionales y gastos operativos.

OptimizaciÃ³n: Uso de @st.cache_data para renderizado ultrarrÃ¡pido sin saturar la base de datos.

ğŸ—‚ï¸ Estructura del Repositorio
Plaintext
â”œâ”€â”€ pipeline_etl.py        # Script central de ExtracciÃ³n, TransformaciÃ³n y Carga (ETL)
â”œâ”€â”€ app.py                 # CÃ³digo fuente del Dashboard interactivo
â”œâ”€â”€ db_portafolio.db       # Base de datos anonimizada (Data Masking)
â”œâ”€â”€ requirements.txt       # Dependencias del entorno
â””â”€â”€ README.md              # DocumentaciÃ³n del proyecto

ğŸ› ï¸ Stack TecnolÃ³gico
Lenguaje: Python 3.x
ExtracciÃ³n y APIs: gspread, google-api-python-client, oauth2
TransformaciÃ³n y Modelado: pandas, sqlite3
VisualizaciÃ³n de Datos: streamlit, plotly.express, altair

ğŸ“Š Impacto en el Negocio
Ahorro de Tiempo: ReducciÃ³n drÃ¡stica de horas invertidas en la consolidaciÃ³n manual de planillas.
Integridad de Datos: EliminaciÃ³n de errores humanos por digitaciÃ³n gracias a la limpieza automatizada.
Control Financiero: Mayor visibilidad del flujo de caja diario y monitoreo estricto de los gastos operativos de la planta y las rutas.

ğŸ” Gobernanza y Seguridad (Data Masking)
Por polÃ­ticas de confidencialidad y Ã©tica profesional:
No se incluyen credenciales API (credenciales.json) en este repositorio.
La base de datos original fue sometida a un riguroso proceso de Data Masking (AnonimizaciÃ³n) mediante un script personalizado en Pandas.
Los nombres de clientes, direcciones especÃ­ficas y descripciones de gastos fueron ofuscados (Cliente 1, Sector A, etc.), manteniendo intactas las relaciones y la coherencia matemÃ¡tica del modelo para demostrar su funcionamiento sin exponer informaciÃ³n sensible de la empresa.
```
### ğŸš€ InstalaciÃ³n y Uso Local
Clonar el repositorio:
```Bash
git clone https://github.com/josue-guillen-dev/dashboard-logistica-agua.git
cd dashboard-logistica-agua
Instalar dependencias:
pip install -r requirements.txt
Ejecutar el dashboard:
streamlit run app.py
```
### ğŸ“ˆ Roadmap y Mejoras Futuras
* Cargas Incrementales (Upsert): TransiciÃ³n de cargas completas (replace) a cargas incrementales (append) para optimizar recursos a medida que el volumen de datos escale.
* MigraciÃ³n de Base de Datos: Escalar de SQLite a PostgreSQL en un entorno Cloud.
* AutomatizaciÃ³n Serverless: Ejecutar el pipeline ETL mediante tareas programadas (Cron jobs o Apache Airflow).

``` text
ğŸ‘¤ Autor: Josue Guillen
ğŸ“Š Perfil: Data Analyst | Especialista en Python, SQL y VisualizaciÃ³n de Datos.
ğŸ“ UbicaciÃ³n: Santiago, Chile
```
ğŸ”— Contacto: [LINKEDIN](https://www.linkedin.com/in/josue-guillen-data/)
